
\section{Introduction} \label{sec:introduction}

Today's autonomous vehicles are fitted with numerous on-board sensors and computers that make them suitable for many civilian and military applications. Complex capabilities like autonomous navigation, surveillance, mapping, and manipulations have transformed the uses of vehicles to improve our daily lives. 
%These new complex capabilities have transformed the uses of vehicles to improve our daily lives. 
With these new enhancements and capabilities, comes the risk of more security vulnerabilities to attacks and failures. An adversary can perform malicious attacks on sensor systems to degrade performance or completely hijack a vehicle to an undesired state. For example, authors in \cite{lee} demonstrated GPS spoofing to take over and change the route of a yacht in the middle of the sea.
%vehicle could be hijacked into an undesired region by spoofing its on-board GPS as demonstrated in \cite{lee}.

%For example, a vehicle could be hijacked into an undesired region by spoofing its on-board GPS as demonstrated in \cite{lee}.

Several different solutions have been proposed to address sensor attacks, from sensor redundancy to complex filtering techniques \cite{fawzi2014secure,6120187,6943080,7330811}. However, a solution for detecting malicious attacks on a system with an unknown model due to changes in dynamics or disturbances has yet to be proposed. This paper introduces a technique to detect sensor attacks on a dynamically changing system without losing control performance. We leverage an adaptive control algorithm to detect sensor under attacks and present an innovative adaptive planning framework to guarantee safety while the vehicle is navigating in an uncertain environment with changes in dynamics (e.g., due to a failure), disturbances (e.g., changes in surface material) and system's configuration (e.g., one or more sensors are removed after detecting that they are compromised). 
%along a trajectory with noisy sensor measurement data in an environment of undesired states. 
Our goal is to distinguish between malicious sensor attacks and dynamical changes or disturbances to the system. Once an attack is detected the system is operating without one or more sensors, hence it is not able to perform as originally designed.  Thus, the vehicle motion plan needs to be adapted based on the remaining available uncompromised sensors and their noise profiles. Adapting motion performance, like speed, ensures that the vehicle will always be safe (e.g., it will not enter undesired states). 

The contribution of this paper comes in two parts: 1) we design a technique to detect sensor attacks on an unknown, dynamically changing system, 2) after the compromised sensors have been removed, we propose a statistical-based motion replanning technique to take into account the new sensor configuration and  guarantee autonomous vehicle safety (i.e., something bad will never happen) and liveness (i.e., something good will eventually happen) while navigating in an obstacle filled environment using limited sensors with different noise profiles. 
To the best of our knowledge this is the first work that considers control and planning adaptation in the context of cyber-physical systems (CPS) security.



\subsection{Related Work}
\label{sec:Related Work}

The subject of both security and safety of autonomous vehicles has been gaining a lot of attention among the robotics  and controls communities due to their potential military and civilian implications.

Researchers have been looking into detection of malicious attacks and resilient state estimation to guarantee vehicle's safety when noide are present. The goal is to prevent attackers from compromising system integrity, control performance, and safety. Numerous control and model based techniques have been recently leveraged to prevent such future events from happening. For example, in \cite{zhu2012resilient} a receding-horizon control algorithm is used to defend against replay attacks. Sensor redundancy based on a linear system model is presented in \cite{6943080} that uses a recursive technique for state estimation while being resilient to attacks. In \cite{7330811}, authors leverage a linear system with sensor redundancy that guarantees a bounded estimation error resilient to attacks. Authors in \cite{fawzi2014secure} characterize an estimation technique when the number of attacks is below a threshold and a resilient output feedback controller. However, the aforementioned work and the majority of the literature on CPS cyber-security typically assume time invariant, static models where dynamics are not changing due to degradation, damage, and environmental or external factors.


When uncertainties arise or changes in the system have occurred, the vehicle needs to alter its plan of motion. In the work \cite{8046382}, reachability analysis leverages the system model and uncertainties to determine inputs to avoid potential obstacles. In \cite{5980508}, Random-Belief Trees are created to guarantee safety in uncertain environments for safe navigation. The work in \cite{6934041} calculates a Risky Area with the help of probability density functions to prevent vehicle collisions. 


In this work,we build a framework to detect malicious sensor attacks on a dynamically changing system to protect integrity of control and safety. We use an adaptive control algorithm to ensure that control performance is not degraded while the system is dynamically changing over time. With an unknown system model with measurement uncertainties, we want to differentiate between sensor attacks and dynamical changes. In \cite{4106038}, the author demonstrates the advantages (i.e., simple to use and robust in nature), modeling steps, and many applications of the \textit{Characteristic Model-Based all-coefficient} (CMBAC) adaptive controller. The CMBAC technique is an efficient option due to the simplicity of the number of parameters to estimate. A discrete-time approach to the CMBAC is utilized to achieve our control objectives.

Differing from previous work, we are able to detect sensor attacks on systems experiencing changing dynamics while maintaining control performance.

The rest of the paper is organized as follows: in section \ref{sec:problem}, we formally define the problems at hand and in section \ref{sec:modeling}, we define all system, noise, and disturbance models. In section \ref{sec:approach}, we discuss the approach taken to attack detection and navigation. Safety and then validation with simulations are presented in Section \ref{sec:simulation}. Lastly, we draw conclusions and discuss future work in Section \ref{sec:conclusion}.


