
\section{Introduction} \label{sec:introduction}

Today's autonomous vehicles are fitted with numerous on-board sensors and computers that make them suitable for many civilian and military applications. These new complex capabilities have transformed the uses of vehicles to improve our daily lives. With these new enhancements and capabilities, comes the risk of more security vulnerabilities to attacks and failures. An adversary now has a greater opportunity of performing malicious attacks on sensor systems to degrade performance or completely lead them to an accident. An example of a malicious attack is when the vehicle's GPS signals are spoofed \cite{lee}, which could lead the vehicle into an undesired region.

Several different solutions have been presented to address these attacks on sensors, from sensor redundancy to complex filtering techniques \cite{fawzi2014secure,pasqualetti2013attack,6120187,6943080,7330811}. However, a solution for detecting malicious attacks on a system with an unknown model due to changes in dynamics or disturbances has yet to be proposed. This paper will introduce a technique to detect sensor attacks on a dynamically changing system without losing control performance by utilizing an adaptive control algorithm and also guaranteeing safety along a trajectory with noisy sensor measurement data in an environment of undesired states. Our goal is to able to distinguish between malicious sensor attacks and changing dynamics or system degradation. A sensor reconfiguration needs to occur with the compromised sensors, leading the system to not perform as originally designed. Furthermore, the vehicle needs to adaptively update its motion dependent on the availability of the uncompromised sensor set's noise profiles. Adapting its motion ensures the vehicle will not enter an undesired region.

The contribution of this paper comes in two parts: 1) we design a technique that is able to detect sensor attacks on an unknown, dynamically changing system, 2) after the compromised sensor has been removed, we propose a motion replanning technique to guarantee autonomous vehicle safety (i.e., something bad will never happen) and liveness (i.e., something good will eventually happen) while navigating in an obstacle filled environment using limited sensors of varying noise profiles. 

%%%%%%%

%The first part will be talking about the problem at hand. What is the problem? What needs to be solved or improved? Explain what has been missing in past techniques (cite them all). For example, we'll be utilizing adaptive control to compensate for failures and dynamical changes.

%Introduce a motivation for the paper. Why am I doing this? Then discuss what I'm going to be proposing in this paper. What am I going to be contributing? Something that no one has done yet, obviously. 

%Adapting of systems with changes/variations in dynamics, sensor noise, and attacks while also adaptively changing the system's motion planning on a high level.

%Discuss and show a timeline of all actions that happen in the simulations.

\subsection{Related Work}
\label{sec:Related Work}

The study of both security and safety of autonomous vehicles has gained a lot of popularity among the robotics community due to their potential military and civilian applications. Various problems researchers have been interested in solving are detection of malicious attacks and guaranteeing vehicle safety when uncertainties are present. Attackers will deliberately attempt to compromise the vehicle's integrity, control performance, and safety. As demonstrated in \cite{lee} the ability to spoof GPS sensors to drive a yacht off course. That work shows attackers with malicious intent would be able to drive a vehicle to an undesired location. Numerous control and model based techniques have been recently leveraged to prevent such future events from happening. For example, in \cite{6426811}, leverages state feedback by changing system dynamics via pole placement. In \cite{zhu2012resilient}, a receding-horizon control algorithm is used to defend against replay attacks. Attack detection using a known linear system model is presented in \cite{pasqualetti2013attack}. Sensor redundancy based on a linear system models are presented in \cite{fawzi2014secure,6943080,7330811}. All of these works presented assume a static system model over time, where dynamics aren't changing due to degradation, damage, and environmental or external factors.

TALK TO NICOLA ON HOW TO STRUCTURE THE RELATED WORK. WE HAVE TWO SEPARATE PROBLEMS AT HAND. (DISCUSS THE PROBLEMS IN SERIES OR PARALLEL).

In this work, we build a framework to which we are able to detect malicious sensor attacks on a dynamically changing system to protect integrity of control and safety. To accomplish this goal, we use an adaptive control algorithm to ensure control performance is not degraded while the system is changing. More uncertainties arise with an unknown system, so we want to be able to differentiate between sensor attacks and dynamical changes or faults in the system. In \cite{tao2003adaptive,Goodwin:2009:AFP:1643720}, a  discrete-time adaptive control approach is utilized to help us achieve these control objectives.

In this work, which is different from related work, we are able to detect sensor attacks on systems experiencing changing dynamics. With these changing dynamics, we are still able to maintain control performance.

The rest of the paper is organized as follows: in Section \ref{sec:problem}, we formally define the problems at hand and Section \ref{sec:modeling}, we define all system, noise, and disturbance models. Section \ref{sec:approach}, we discuss the approach taken to attack detection and navigational safety and then validation with simulation and experiments in Section \ref{sec:simulation}. Lastly, we draw conclusions and discuss future work in Section \ref{sec:conclusion}.

